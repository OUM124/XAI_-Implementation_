{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd16380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reproduction of Section 3.5: Text Classification with SVMs.\n",
    "Dataset: 20 Newsgroups (Atheism vs. Christianity).\n",
    "Goal: Show that high accuracy is based on artifacts (Headers).\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "\n",
    "# Add project root to python path so we can import src\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.explainers.lime_text import LimeTextExplainer\n",
    "from src.utils.visualization import Visualizer\n",
    "\n",
    "def run_experiment():\n",
    "    print(\"Loading 20 Newsgroups dataset (Atheism vs. Christianity)...\")\n",
    "    categories = ['alt.atheism', 'soc.religion.christian']\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "    \n",
    "    class_names = ['Atheism', 'Christianity']\n",
    "    \n",
    "    # 1. Train the Black Box Model (SVM with RBF Kernel - per paper)\n",
    "    # The paper mentions \"SVM with RBF kernel... trained on unigrams\".\n",
    "    print(\"Training SVM (this might take a minute)...\")\n",
    "    vectorizer = TfidfVectorizer(lowercase=False) # lowercase=False to keep capitalized headers visible\n",
    "    model = SVC(kernel='rbf', probability=True) # probability=True is needed for LIME\n",
    "    \n",
    "    # Create a pipeline\n",
    "    c = make_pipeline(vectorizer, model)\n",
    "    c.fit(newsgroups_train.data, newsgroups_train.target)\n",
    "    \n",
    "    # 2. Verify Accuracy\n",
    "    pred_test = c.predict(newsgroups_test.data)\n",
    "    f1 = metrics.f1_score(newsgroups_test.target, pred_test)\n",
    "    print(f\"Model F1 Score on Test Set: {f1:.4f}\")\n",
    "    print(\"Model seems trustworthy based on metrics... or is it?\")\n",
    "\n",
    "    # 3. LIME Explanation\n",
    "    # We pick a specific instance that looks suspicious. \n",
    "    # In the paper, they show an instance where \"Posting\" and \"Host\" are key.\n",
    "    # Let's pick a random instance from the test set.\n",
    "    idx = 83 # Arbitrary index, or we can loop to find a good example\n",
    "    text_instance = newsgroups_test.data[idx]\n",
    "    true_label = newsgroups_test.target[idx]\n",
    "    \n",
    "    print(\"\\n--- Explaining Instance #{} ---\".format(idx))\n",
    "    print(f\"True Label: {class_names[true_label]}\")\n",
    "    print(f\"Model Prediction: {class_names[c.predict([text_instance])[0]]}\")\n",
    "    print(f\"Text Snippet: {text_instance[:300]}...\\n\")\n",
    "\n",
    "    # Initialize our LIME Explainer\n",
    "    explainer = LimeTextExplainer(kernel_width=25, random_state=42, verbose=False)\n",
    "    \n",
    "    # Explain the predicted class\n",
    "    # The pipeline.predict_proba takes a list of strings\n",
    "    print(\"Running LIME...\")\n",
    "    exp = explainer.explain_instance(\n",
    "        text_instance, \n",
    "        c.predict_proba, \n",
    "        labels=(c.predict([text_instance])[0],), # Explain the predicted class\n",
    "        num_features=6, \n",
    "        num_samples=2000\n",
    "    )\n",
    "    \n",
    "    # 4. Visualize\n",
    "    viz = Visualizer()\n",
    "    predicted_idx = list(exp.keys())[0] # Get the class we explained\n",
    "    viz.visualize_text(exp[predicted_idx])\n",
    "    \n",
    "    print(\"\\nANALYSIS:\")\n",
    "    print(\"If you see words like 'Subject', 'From', 'Organization', or 'Re' with high bars,\")\n",
    "    print(\"you have successfully reproduced the paper's finding: the model is overfitting to headers!\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1b1e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 Newsgroups dataset (Atheism vs. Christianity)...\n",
      "Training SVM (this might take a minute)...\n",
      "Model F1 Score on Test Set: 0.9303\n",
      "Model seems trustworthy based on metrics... or is it?\n",
      "\n",
      "--- Explaining Instance #83 ---\n",
      "True Label: Atheism\n",
      "Model Prediction: Atheism\n",
      "Text Snippet: From: johnchad@triton.unm.edu (jchadwic)\n",
      "Subject: Another request for Darwin Fish\n",
      "Organization: University of New Mexico, Albuquerque\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: triton.unm.edu\n",
      "\n",
      "Hello Gang,\n",
      "\n",
      "There have been some notes recently asking where to obtain the DARWIN fish.\n",
      "This is the same question I have...\n",
      "\n",
      "Running LIME...\n",
      "\n",
      "=== LIME Explanation ===\n",
      "Target Class: 0\n",
      "Local Linear Prediction: 1.0390\n",
      "Features:\n",
      "\u001b[92m            unm | 0.3053 ███████████████\u001b[0m\n",
      "\u001b[92m            edu | 0.1125 █████\u001b[0m\n",
      "\u001b[92m           Host | 0.1083 █████\u001b[0m\n",
      "\u001b[92m        Posting | 0.1047 █████\u001b[0m\n",
      "\u001b[92m           NNTP | 0.0904 ████\u001b[0m\n",
      "\u001b[91m             or | -0.0053 \u001b[0m\n",
      "\n",
      "ANALYSIS:\n",
      "If you see words like 'Subject', 'From', 'Organization', or 'Re' with high bars,\n",
      "you have successfully reproduced the paper's finding: the model is overfitting to headers!\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
