# LIME: Explaining the Predictions of Any Classifier (Reproduction)

This repository contains a Python reproduction of the seminal paper **"Why Should I Trust You?: Explaining the Predictions of Any Classifier"** (Ribeiro et al., KDD 2016).

The goal of this project is to implement **LIME** (Local Interpretable Model-agnostic Explanations) and **SP-LIME** (Submodular Pick) from scratch to demonstrate that high accuracy on validation sets does not imply a trustworthy model.

---

## ðŸ§ª Key Results

### 1. The "Husky vs. Wolf" Experiment (Image)

We reproduced the experiment described in **Section 6.4**. We trained a classifier on a biased dataset where **Wolves appear on Snow** and **Huskies on Grass**.

- **Prediction:** The model predicts "Wolf" for a Husky sitting on snow.
- **LIME Explanation:** As shown below, the explanation highlights only the background (snow/artifacts), proving the model ignores the animal entirely. It is a **"Snow Detector,"** not a Wolf detector, most importantly the model doesn't base its prediction on the caracteristics of the animal, but rather on some random artifacts.  

![Husky vs Wolf Explanation](results/husky_wolf_explanation.png)

### 2. The "Un-Trustworthy" Classifier (Text & SP-LIME)

We reproduced **Section 6.2** using the **20 Newsgroups** dataset. We trained an SVM that achieves 95% accuracy but relies on spurious artifacts (email headers).

- **Random Selection:** Often shows valid predictions, misleading the user into trusting the model.
- **SP-LIME Selection:** Mathematically selects a representative set. It successfully surfaces instances where the model relies on `Organization`, `Posting-Host`, and `Nntp-Posting`, identifying data leakage immediately.

![SP-LIME Text Results](results/sp_lime_text_results.png)

---

## ðŸ“‚ Project Structure
```
lime_reproduction/
â”‚
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .gitignore             
â”‚
â”œâ”€â”€ data/                   # Raw images and text datasets (not in git)
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ husky_vs_wolf/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ wolf_snow/      # 5 images of wolves on snow
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ husky_grass/    # 5 images of huskies on grass
â”‚   â”‚   â”‚   â””â”€â”€ val/
â”‚   â”‚   â”‚       â””â”€â”€ husky_snow/     # 1 image of husky on snow (trick image)
â”‚   
â”‚
â”‚
â”œâ”€â”€ src/                    # Core Library
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ core/               # Mathematical Engine
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py         # Abstract LIME Base Class
â”‚   â”‚   â”œâ”€â”€ k_lasso.py      # K-LASSO Solver (Algorithm 1)
â”‚   â”‚   â””â”€â”€ sp_lime.py      # Submodular Pick (Algorithm 2)
â”‚   â”‚
â”‚   â”œâ”€â”€ explainers/         # Domain Implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ lime_text.py    # Text Perturbation & Vectorization
â”‚   â”‚   â””â”€â”€ lime_image.py   # Image Segmentation & Masking
â”‚   â”‚
â”‚   â””â”€â”€ utils/              # Helpers
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ segmentation.py # Quickshift/SLIC wrappers
â”‚       â”œâ”€â”€ visualization.py# Plotting explanations
â”‚
â”œâ”€â”€ experiments/            # Reproducing Paper Results
â”‚   â”œâ”€â”€ 01_text_reproduction.ipynb      
â”‚   â”œâ”€â”€ 02_husky_vs_wolf.ipynb     
â”‚   â””â”€â”€ 04_sp_lime_global.ipynb      
â”‚
â”œâ”€â”€ results/                # Generated plots and figures
â”‚   â”œâ”€â”€ husky_wolf_explanation.png
|   |â”€â”€ lime.png
â”‚   â””â”€â”€ sp_lime_text_results.png
â”‚
â””â”€â”€ tests/                  # Unit Tests
    â”œâ”€â”€ test_k_lasso.py
    â”œâ”€â”€ test_text.py
    â””â”€â”€ test_image.py
```

---

## ðŸš€ Installation

### 1. Clone the repository
```bash
git clone https://github.com/OUM124/lime-reproduction.git
cd lime-reproduction
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

**Key libraries:** `numpy`, `scikit-learn`, `scikit-image`, `matplotlib`, `Pillow`, `scipy`, `jupyter`

---

## ðŸ’» Usage & Reproduction

### Experiment 1: Husky vs. Wolf (Image Bias)

This demonstrates **Local Interpretability** on a broken image classifier.

1. **Prepare data:** Ensure you have training images in `data/raw/husky_vs_wolf/`:
   - `train/wolf_snow/` - 5 images of Wolves on Snow
   - `train/husky_grass/` - 5 images of Huskies on Grass
   - `val/husky_snow/` - 1 image of Husky on Snow (trick image)

2. **Run the notebook:**
```bash
   jupyter notebook experiments/03_bad_classifier.ipynb
```

3. **Output:** A visualization showing the superpixels responsible for the prediction (snow, not the dog!).

---

### Experiment 2: Detecting Data Leakage (SP-LIME on Text)

This demonstrates **Global Interpretability** using the Submodular Pick algorithm.

1. **Run the experiment:**
```bash
   python experiments/04_sp_lime_global.ipynb
```

2. **Output:** The top instances selected by SP-LIME will display features like `Organization`, `Posting-Host`, or `Nntp-Posting-Host`, revealing the model is cheating by relying on email metadata.

---

## ðŸ§  Implementation Details

### LIME (Local Interpretable Model-agnostic Explanations)

We implemented the core LIME logic in `src/core/base.py`.

- **Perturbation:** Generate neighborhood data by randomly masking superpixels (images) or removing words (text).
- **Distance Kernel:** Weight samples using an exponential kernel: 
```
  Ï€_x(z) = exp(-D(x, z)Â² / ÏƒÂ²)
```
- **K-LASSO:** Implemented Algorithm 1 from the paper to select K features and fit a weighted linear model.

**Key equation:**
```
Î¾(x) = argmin_{gâˆˆG} L(f, g, Ï€_x) + Î©(g)
```

### SP-LIME (Submodular Pick)

We implemented Algorithm 2 in `src/core/sp_lime.py`.

1. Constructs an **Explanation Matrix W** (n Ã— d')
2. Computes **Global Feature Importance I**
3. Uses a **greedy algorithm** to maximize the coverage function:
```
   c(V, W, I) = Î£ 1[âˆƒiâˆˆV: W_ij > 0] Â· I_j
```

This ensures the selected instances explain diverse model behaviors (non-redundant coverage).

---

## ðŸ“Š Results

### Quantitative Results

| Experiment | Metric | Value | Interpretation |
|------------|--------|-------|----------------|
| Husky vs Wolf | Accuracy | 90% | High accuracy, but... |
| Husky vs Wolf | Snow Detection | 100% | ...model only detects snow! |
| 20 Newsgroups (SVM) | Validation Accuracy | 95% | Looks good, but... |
| 20 Newsgroups (SVM) | Metadata Features | >50% | ...relies on leaked headers |

### Qualitative Results

**Before LIME:** Users trust a 95% accurate model.

**After LIME:** Users discover the model is a "header detector" or "snow detector," not a semantic classifier.

---

## ðŸ§ª Running Tests
```bash
pytest tests/
```

Or run individual tests:
```bash
python -m pytest tests/test_k_lasso.py -v
python -m pytest tests/test_text.py -v
python -m pytest tests/test_image.py -v
```

---

## ðŸ“š Reference

This code is a reproduction of the following paper:

> **"Why Should I Trust You?" Explaining the Predictions of Any Classifier**  
> Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin  
> KDD 2016, San Francisco, CA, USA  
> [Paper Link](https://arxiv.org/abs/1602.04938) | [Original Code](https://github.com/marcotcr/lime)




## ðŸ“§ Contact

 [@OUM124](https://github.com/OUM124)

Project Link: [https://github.com/OUM124/lime-reproduction](https://github.com/OUM124/lime-reproduction)

---

